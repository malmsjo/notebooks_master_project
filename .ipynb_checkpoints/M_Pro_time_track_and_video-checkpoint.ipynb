{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import imutils\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import watershed\n",
    "from scipy import ndimage\n",
    "import collections\n",
    "from skimage.draw import circle, line\n",
    "from skimage.measure import regionprops\n",
    "import tqdm\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "# the GPU id to use (0, 1, 2 or 3)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "   return int(text) if text.isdigit() else text\n",
    "def natural_keys(text):\n",
    "   return [atoi(c) for c in re.split('(\\d+)', text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "via = '/home/jovyan/well_B4_viedo_cell'\n",
    "directory = os.mkdir(via) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "for filename in sorted(glob.glob('/home/jovyan/Images_well_B4_1/*.tiff'), key=natural_keys): \n",
    "    im=cv2.imread(filename)\n",
    "   \n",
    "    image_list.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_0 = image_list[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "    \n",
    "cx = []\n",
    "cy = []\n",
    "\n",
    "shifted = cv2.pyrMeanShiftFiltering(i_0, 10, 51)\n",
    "gray = cv2.cvtColor(shifted,cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray, 20, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "D = ndimage.distance_transform_edt(thresh)\n",
    "localMax = peak_local_max(D, indices=False, min_distance=9, labels=thresh)\n",
    "markers = ndimage.label(localMax, structure=np.ones((3, 3)))[0]\n",
    "labels = watershed(-D, markers, mask=thresh)\n",
    "    \n",
    "    \n",
    "\n",
    "for label in np.unique(labels):\n",
    "    if label == 0:\n",
    "        continue\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    mask = np.zeros(gray.shape, dtype='uint8')\n",
    "    mask[labels == label] = 255\n",
    "    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    ((x, y), r) = cv2.minEnclosingCircle(c)\n",
    "        \n",
    "        \n",
    "        \n",
    "    cx.append(int(x))\n",
    "    cy.append(int(y))\n",
    "        \n",
    "\n",
    "    data = {'X':cx,'Y':cy}\n",
    "        \n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    \n",
    "d = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = d.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateMask(img, circle_ratio=10, background_ratio=8): #10 and 8 standaard\n",
    "    # ratio = size of seed to make around annotation\n",
    "    # ratio is for the mask edge which is set to not object\n",
    "    # for the watershed grow out from the seed and in from the edge\n",
    "    size = img.shape[0], img.shape[1]\n",
    "\n",
    "    xc, yc = int(size[0] / 2), int(size[1] / 2)\n",
    "\n",
    "    markers = np.zeros([img.shape[0], img.shape[1]], dtype=np.int32)\n",
    "\n",
    "    # set object seed #\n",
    "    # markers[xc - 2:xc + 2, yc - 2:yc + 2] = 2\n",
    "\n",
    "    rr, cc = circle(xc, yc, circle_ratio, img.shape)\n",
    "    markers[rr, cc] = 2\n",
    "\n",
    "    # set backgound seed #\n",
    "\n",
    "    markers[0:int(size[0] / background_ratio), 0:size[1]] = 1\n",
    "\n",
    "    markers[int(size[0] * (background_ratio - 1) / background_ratio):size[0], 0:size[1]] = 1\n",
    "\n",
    "    markers[0:size[0], 0:int(size[0] / background_ratio)] = 1\n",
    "\n",
    "    markers[0:size[0], int(size[1] * (background_ratio - 1) / background_ratio):size[1]] = 1\n",
    "\n",
    "    return markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_new_centroid(crop, shape, coords):\n",
    "    mask = generateMask(crop, circle_ratio=10, background_ratio=8) #10 and 8 standaard\n",
    "    ret_mask = mask.copy()\n",
    "\n",
    "    img_rgb = cv2.cvtColor(((crop / np.max(crop)) * 255).astype('uint8'), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    cv2.watershed(img_rgb, mask)\n",
    "    mask[mask != 2] = 0\n",
    "    mask[mask == 2] = 1\n",
    "\n",
    "    m = np.zeros(shape, dtype='uint8')\n",
    "\n",
    "    m[np.maximum(coords[1] - offset, 0):np.minimum(coords[1] + offset, shape[0]),\n",
    "    np.maximum(coords[0] - offset, 0):np.minimum(coords[0] + offset, shape[1])] = mask\n",
    "\n",
    "    rprop = regionprops(m)\n",
    "\n",
    "    c = rprop[0].centroid\n",
    "\n",
    "    return c, mask, ret_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = (glob.glob('/home/jovyan/Images_well_B4_1/*.tiff'))\n",
    "\n",
    "files = sorted(f, key=natural_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/65 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.0) /io/opencv/modules/imgproc/src/color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function 'cv::impl::{anonymous}::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::impl::{anonymous}::Set<1>; VDcn = cv::impl::{anonymous}::Set<3, 4>; VDepth = cv::impl::{anonymous}::Set<0, 2, 5>; cv::impl::{anonymous}::SizePolicy sizePolicy = (cv::impl::<unnamed>::SizePolicy)2u; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 4\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5f4bd9e12806>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m             np.maximum(coords[cell_nr][0] - offset,0):np.minimum(coords[cell_nr][0] + offset,im.shape[1])]\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_new_centroid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcell_nr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mrr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcell_nr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcell_nr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-d43c32059276>\u001b[0m in \u001b[0;36mextract_new_centroid\u001b[0;34m(crop, shape, coords)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mret_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimg_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_GRAY2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatershed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.0) /io/opencv/modules/imgproc/src/color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function 'cv::impl::{anonymous}::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::impl::{anonymous}::Set<1>; VDcn = cv::impl::{anonymous}::Set<3, 4>; VDepth = cv::impl::{anonymous}::Set<0, 2, 5>; cv::impl::{anonymous}::SizePolicy sizePolicy = (cv::impl::<unnamed>::SizePolicy)2u; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 4\n"
     ]
    }
   ],
   "source": [
    "all_coords = []\n",
    "\n",
    "offset = 32 # distance out from center so with 100 gives 200x200 box\n",
    "\n",
    "for cell_nr in tqdm.tqdm(range(len(coords) - 1)):\n",
    "\n",
    "    cell_coords = []\n",
    "\n",
    "    im = cv2.imread(files[0], -1)\n",
    "\n",
    "    path = np.zeros(im.shape, dtype='uint8')\n",
    "\n",
    "    crop = im[np.maximum(coords[cell_nr][1] - offset,0):np.minimum(coords[cell_nr][1] + offset,im.shape[0]),\n",
    "            np.maximum(coords[cell_nr][0] - offset,0):np.minimum(coords[cell_nr][0] + offset,im.shape[1])]\n",
    "\n",
    "    c, mask, ret_mask = extract_new_centroid(crop, im.shape, coords[cell_nr])\n",
    "\n",
    "    rr, cc = line(coords[cell_nr][1], coords[cell_nr][0], int(round(c[0])), int(round(c[1])))\n",
    "    path[rr, cc] = 16000 # number could be anything\n",
    "\n",
    "    coord = np.round(c).astype('int')[::-1]\n",
    "\n",
    "    for file in files[1:]:\n",
    "        im = cv2.imread(file, -1)\n",
    "\n",
    "        crop = im[np.maximum(coord[1] - offset, 0):np.minimum(coord[1] + offset, im.shape[0]),\n",
    "                np.maximum(coord[0] - offset, 0):np.minimum(coord[0] + offset, im.shape[1])]\n",
    "\n",
    "        c, mask, ret_mask = extract_new_centroid(crop, im.shape, coord)\n",
    "\n",
    "        rr, cc = line(coord[1], coord[0], int(round(c[0])), int(round(c[1])))\n",
    "        path[rr, cc] = 16000\n",
    "\n",
    "            # im[path != 0] = 16000\n",
    "            # plt.imshow(crop)\n",
    "            # plt.imshow(ret_mask, alpha = 0.5)\n",
    "            # plt.show(block=False)\n",
    "            # plt.pause(0.001)\n",
    "            # plt.close()\n",
    "            # plt.subplot(121), plt.imshow(crop), plt.imshow(mask, alpha=0.4)\n",
    "            # plt.subplot(122), plt.imshow(crop), plt.imshow(ret_mask, alpha=0.4)\n",
    "            # plt.show()\n",
    "\n",
    "        coord = np.round(c).astype('int')[::-1]\n",
    "\n",
    "        cell_coords.append(list(coord))\n",
    "\n",
    "    all_coords.append(cell_coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=list(df.columns)\n",
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, i in tqdm.tqdm(enumerate(l)):\n",
    "\n",
    "    d_1 = df.iloc[:,ix]\n",
    "\n",
    "\n",
    "\n",
    "    df3 = d_1.apply(pd.Series)\n",
    "    df3.columns = ['X', 'Y']\n",
    "\n",
    "    image_list = []\n",
    "    for filename in sorted(glob.glob('/home/jovyan/Images_well_B4_1/*.tiff'), key=natural_keys): \n",
    "        im=cv2.imread(filename)\n",
    "\n",
    "        image_list.append(im)\n",
    "\n",
    "    image = image_list[ix]\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(df3)):\n",
    "        x.append(df3.iloc[i,0])\n",
    "        y.append(df3.iloc[i,1])\n",
    "\n",
    "\n",
    "\n",
    "    for idx, i in enumerate(x):\n",
    "\n",
    "\n",
    "\n",
    "        cv2.circle(image, (x[idx], y[idx]), 3, (0, 255, 255), -1)\n",
    "        cv2.putText(image, \"{0}\".format(idx), (x[idx] - 20, y[idx] - 20),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    #plt.imshow(image)\n",
    "\n",
    "\n",
    "\n",
    "    im = Image.fromarray(image)\n",
    "    im.save(\"/home/jovyan/well_B4_viedo_cell/image_{0}.tiff\".format(ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = '/home/jovyan/well_B5_viedo_cell/'\n",
    "video_name = 'video_cell_wellb4.avi'\n",
    "\n",
    "images = [img for img in sorted(os.listdir(image_folder), key=natural_keys) if img.endswith(\".tiff\")]\n",
    "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "video = cv2.VideoWriter(video_name, 0, 1, (width,height))\n",
    "\n",
    "for image in images:\n",
    "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
