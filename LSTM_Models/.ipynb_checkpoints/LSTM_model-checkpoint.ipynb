{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image \n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn import preprocessing\n",
    "import tqdm\n",
    "from numpy import loadtxt\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split('(\\d+)', text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(true,preds):\n",
    "    conf_matx = confusion_matrix(true, preds)\n",
    "    sns.heatmap(conf_matx, annot=True,annot_kws={\"size\": 12},fmt='g', cbar=False, cmap=plt.cm.Blues) #'viridis'\n",
    "    #plt.savefig('/home/jovyan/img1.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return conf_matx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages():\n",
    "\n",
    "    feat_list = []\n",
    "    \n",
    "\n",
    "    for filename in sorted(glob.glob('/home/jovyan/DATA_MASTER_PROJECT/LSTM/Feature_LSTM_Train/*.npy'), key=natural_keys): \n",
    "        feat_list.append(np.load(filename))\n",
    "\n",
    "    x_orig = np.reshape(feat_list, (len(feat_list),10, 64))\n",
    "    \n",
    "    path = '/home/jovyan/DATA_MASTER_PROJECT/LSTM/lstm_train.csv'     \n",
    "    labels = pd.read_csv(path, usecols=[\"Type\", \"Category\"],\n",
    "                       sep=\",\" )\n",
    "    y_orig = np.array(labels['Category'])\n",
    "\n",
    "    return x_orig, y_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = loadImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 10, 64), (100,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 10, 64), (20, 10, 64), (80,), (20,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x,y, test_size=0.2, random_state=999 )\n",
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights = [2.96296296 0.54421769 1.21212121]\n"
     ]
    }
   ],
   "source": [
    "weights = class_weight.compute_class_weight('balanced', np.unique(y_train),y_train)\n",
    "print('weights = ' + str(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = keras.utils.to_categorical(y_train)\n",
    "y_v = keras.utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Sequential()\n",
    "m.add(LSTM(10, input_shape = (x_train.shape[1],x_train.shape[2])))\n",
    "m.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(lr=1e-3)\n",
    "\n",
    "m.compile(loss= keras.losses.categorical_crossentropy, optimizer=opt, metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/100\n",
      "80/80 [==============================] - 4s 45ms/sample - loss: 1.1888 - accuracy: 0.3250 - val_loss: 1.2550 - val_accuracy: 0.1500\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 483us/sample - loss: 1.1097 - accuracy: 0.3875 - val_loss: 1.1666 - val_accuracy: 0.2000\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 377us/sample - loss: 1.0372 - accuracy: 0.4875 - val_loss: 1.0956 - val_accuracy: 0.2500\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 387us/sample - loss: 0.9802 - accuracy: 0.5750 - val_loss: 1.0408 - val_accuracy: 0.3500\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 335us/sample - loss: 0.9325 - accuracy: 0.6500 - val_loss: 0.9943 - val_accuracy: 0.6500\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 337us/sample - loss: 0.8956 - accuracy: 0.7375 - val_loss: 0.9538 - val_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 337us/sample - loss: 0.8588 - accuracy: 0.7375 - val_loss: 0.9176 - val_accuracy: 0.6500\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 346us/sample - loss: 0.8265 - accuracy: 0.7500 - val_loss: 0.8838 - val_accuracy: 0.6500\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 375us/sample - loss: 0.7936 - accuracy: 0.7875 - val_loss: 0.8520 - val_accuracy: 0.7000\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 336us/sample - loss: 0.7607 - accuracy: 0.7875 - val_loss: 0.8203 - val_accuracy: 0.7000\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 338us/sample - loss: 0.7274 - accuracy: 0.8000 - val_loss: 0.7884 - val_accuracy: 0.7000\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 381us/sample - loss: 0.6946 - accuracy: 0.8000 - val_loss: 0.7563 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 367us/sample - loss: 0.6639 - accuracy: 0.8000 - val_loss: 0.7240 - val_accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 361us/sample - loss: 0.6347 - accuracy: 0.8000 - val_loss: 0.6909 - val_accuracy: 0.7500\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 378us/sample - loss: 0.6035 - accuracy: 0.8125 - val_loss: 0.6577 - val_accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 326us/sample - loss: 0.5736 - accuracy: 0.8125 - val_loss: 0.6246 - val_accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 361us/sample - loss: 0.5430 - accuracy: 0.8125 - val_loss: 0.5935 - val_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 358us/sample - loss: 0.5119 - accuracy: 0.8375 - val_loss: 0.5642 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 317us/sample - loss: 0.4811 - accuracy: 0.8750 - val_loss: 0.5394 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 315us/sample - loss: 0.4522 - accuracy: 0.8750 - val_loss: 0.5137 - val_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 305us/sample - loss: 0.4234 - accuracy: 0.8875 - val_loss: 0.4879 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 349us/sample - loss: 0.3973 - accuracy: 0.9000 - val_loss: 0.4604 - val_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 322us/sample - loss: 0.3717 - accuracy: 0.9125 - val_loss: 0.4373 - val_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 320us/sample - loss: 0.3494 - accuracy: 0.9250 - val_loss: 0.4170 - val_accuracy: 0.8500\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 321us/sample - loss: 0.3276 - accuracy: 0.9375 - val_loss: 0.3993 - val_accuracy: 0.8500\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 333us/sample - loss: 0.3074 - accuracy: 0.9375 - val_loss: 0.3841 - val_accuracy: 0.8500\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 296us/sample - loss: 0.2888 - accuracy: 0.9375 - val_loss: 0.3709 - val_accuracy: 0.8500\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 343us/sample - loss: 0.2703 - accuracy: 0.9625 - val_loss: 0.3587 - val_accuracy: 0.8500\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 323us/sample - loss: 0.2531 - accuracy: 0.9875 - val_loss: 0.3472 - val_accuracy: 0.8500\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 313us/sample - loss: 0.2360 - accuracy: 0.9875 - val_loss: 0.3380 - val_accuracy: 0.8500\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 308us/sample - loss: 0.2216 - accuracy: 0.9875 - val_loss: 0.3321 - val_accuracy: 0.8500\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 280us/sample - loss: 0.2081 - accuracy: 0.9875 - val_loss: 0.3264 - val_accuracy: 0.8500\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 283us/sample - loss: 0.1963 - accuracy: 0.9875 - val_loss: 0.3189 - val_accuracy: 0.8500\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s 342us/sample - loss: 0.1851 - accuracy: 0.9875 - val_loss: 0.3124 - val_accuracy: 0.8500\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s 320us/sample - loss: 0.1751 - accuracy: 1.0000 - val_loss: 0.3029 - val_accuracy: 0.8500\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s 359us/sample - loss: 0.1664 - accuracy: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.8500\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s 351us/sample - loss: 0.1580 - accuracy: 1.0000 - val_loss: 0.2840 - val_accuracy: 0.8500\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s 331us/sample - loss: 0.1507 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.8500\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s 318us/sample - loss: 0.1437 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.8500\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s 308us/sample - loss: 0.1375 - accuracy: 1.0000 - val_loss: 0.2637 - val_accuracy: 0.8500\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s 354us/sample - loss: 0.1321 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.8500\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s 318us/sample - loss: 0.1274 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.8500\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s 305us/sample - loss: 0.1226 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.8500\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s 314us/sample - loss: 0.1182 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.8500\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s 340us/sample - loss: 0.1141 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.8500\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s 256us/sample - loss: 0.1099 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.8500\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s 278us/sample - loss: 0.1062 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.8500\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s 285us/sample - loss: 0.1026 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.8500\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s 299us/sample - loss: 0.0990 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.8500\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s 234us/sample - loss: 0.0960 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.8500\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s 287us/sample - loss: 0.0933 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.8500\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s 295us/sample - loss: 0.0902 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9000\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s 313us/sample - loss: 0.0875 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9000\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s 249us/sample - loss: 0.0849 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9000\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s 245us/sample - loss: 0.0826 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9000\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s 296us/sample - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9000\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s 265us/sample - loss: 0.0781 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9000\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s 276us/sample - loss: 0.0761 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.9500\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s 292us/sample - loss: 0.0743 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9500\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s 278us/sample - loss: 0.0725 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9500\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s 278us/sample - loss: 0.0706 - accuracy: 1.0000 - val_loss: 0.1786 - val_accuracy: 0.9500\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s 335us/sample - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 0.9500\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s 243us/sample - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9500\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s 233us/sample - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9500\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s 239us/sample - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.1626 - val_accuracy: 0.9500\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s 259us/sample - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9500\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s 255us/sample - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9500\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s 312us/sample - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.1547 - val_accuracy: 0.9500\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s 319us/sample - loss: 0.0588 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9500\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s 272us/sample - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9500\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s 253us/sample - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9500\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s 249us/sample - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 0.9500\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s 273us/sample - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.1444 - val_accuracy: 0.9500\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s 297us/sample - loss: 0.0531 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9500\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s 294us/sample - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9500\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s 323us/sample - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9500\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s 290us/sample - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9500\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s 307us/sample - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9500\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s 348us/sample - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.9500\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s 265us/sample - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9500\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s 260us/sample - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9500\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s 276us/sample - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.1332 - val_accuracy: 0.9500\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s 300us/sample - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9500\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s 264us/sample - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9500\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s 266us/sample - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9500\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s 274us/sample - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9500\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s 282us/sample - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.1270 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s 302us/sample - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s 258us/sample - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.1245 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s 299us/sample - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s 297us/sample - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s 312us/sample - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.1202 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s 265us/sample - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s 256us/sample - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s 305us/sample - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.1159 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s 334us/sample - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.1147 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s 321us/sample - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s 352us/sample - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s 339us/sample - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s 282us/sample - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "m4_h = m.fit(x_train,y_t,\n",
    "                \n",
    "                epochs=epochs,\n",
    "                validation_data = (x_val,y_v), \n",
    "                \n",
    "                class_weight = weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
